{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "You are a professional JSON programmer. Your task is to extract data from the text and represent it as JSON.\n",
    "\n",
    "Output the result ONLY in JSON format.\n",
    "The JSON structure must be EXACTLY like this:\n",
    "{\n",
    "  \"entities\": [\n",
    "    {\n",
    "      \"name\": \"Entity Name\",\n",
    "      \"description\": \"Concise description based ONLY on the text\"\n",
    "    }\n",
    "    // ... other entities found\n",
    "  ],\n",
    "  \"relationships\": [\n",
    "    {\n",
    "\t\"source\": \"Source Entity Name\", \n",
    "\t\"description\": \"Relationship Description\", \n",
    "\t\"target\": \"Target Entity Name\"\n",
    "    }\n",
    "    // ... other relationships found \n",
    "  ]\n",
    "}\n",
    "**Rules:**\n",
    "1.  **entities**: List entities with descriptions from the text.\n",
    "2.  **relationships**: List relationships. Use EXACT names from `entities`.\n",
    "3.  Use ONLY information from the text.\n",
    "4.  Your response MUST be ONLY valid JSON. Nothing else. (start with ```json)\n",
    "\n",
    "**TEXT TO ANALYZE:**\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tempalte = str(\"\"\"\n",
    "<|im_start|>system\n",
    "{system_message}<|im_end|>\n",
    "<|im_start|>user\n",
    "{prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\"\n",
    "Olga Dmitrievna and Semyon's Cabin\n",
    "A poster of Fantômas can be seen on the wall.\n",
    "Near the Fantômas poster is a poster of a bitard.\n",
    "A poster of a typical bitard hangs on the right wall.\n",
    "A hammer lies under Olga Dmitrievna's bed, referencing the Banhammer-chan mascot, which served as the prototype for the counselor.\n",
    "The map in each cabin shows its occupants. In the counselor and Semyon's cabin, Semyon is depicted as the same bitard with a bag on his head.\n",
    "Slavya and Zhenya's Cabin\n",
    "A poster of Mitsgol (the basis for Mitsgël, which served as the prototype for Zhenya) can be seen on the left wall.\n",
    "Famous paintings by Vasnetsov hang on the right wall.\n",
    "The shelves above Zhenya's bed are filled with books, indicating that she reads all the time, even in her cabin (since she spends the rest of her time in the library).\n",
    "Alya and Ulyana's Cabin\n",
    "A poster from the anime \"Detroit Metal City\" hangs above Alya's bed.\n",
    "A poster of Stalin from the game \"Stalin vs. Martians\" hangs above Ulyana's bed.\n",
    "Next to the Stalin poster is a poster of a kitten named Gav.\n",
    "On the other side of the Stalin poster is a poster of Soviet-era hockey players, likely one of the following: Larionov, Krutov, Fetisov, Makarov, Kasatonov.\n",
    "The wallpaper in the cabin features drawings of a sickle and hammer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сторонние импорты\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "# from set_enviroment import *\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# локальные импорты\n",
    "\n",
    "llm = ChatOpenAI(model = os.getenv(\"RAG_LLM_MODEL\"), base_url = os.getenv('RAG_BASE_URL'), temperature=0.7, top_p=0.9, max_tokens=None, timeout=None) | SimpleJsonOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in llm.stream(PROMPT + user_input):\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def get_input_files(files_dir):\n",
    "    'Return list of txt, docx, pdf documents'\n",
    "    \n",
    "    def load_file(Loader = TextLoader):\n",
    "        return Loader(os.path.join(files_dir, file)).load()\n",
    "    \n",
    "    files = []\n",
    "    for file in os.listdir(files_dir):\n",
    "        if file.endswith(\".txt\"):\n",
    "            files.append(load_file())\n",
    "        if file.endswith(\".docx\"):\n",
    "            files.append(load_file(Docx2txtLoader))\n",
    "        if file.endswith(\".pdf\"):\n",
    "            files.append(load_file(PyPDFLoader))\n",
    "\n",
    "    return files\n",
    "\n",
    "def get_chunks(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,  # Размер чанка\n",
    "        chunk_overlap=200  # Перекрытие чанков\n",
    "    )\n",
    "\n",
    "    return text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = get_chunks(get_input_files(os.getenv(\"DATA_PATH\")))\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response2 = llm.invoke(str(prompt_tempalte.format(\n",
    "#     system_message=PROMPT,\n",
    "#     prompt=user_input\n",
    "# )))\n",
    "\n",
    "# response1, response2 = llm.batch(\n",
    "#     [\n",
    "#         str(prompt_tempalte.format(\n",
    "#             system_message=PROMPT,\n",
    "#             prompt=user_input\n",
    "#         )),\n",
    "#         str(prompt_tempalte.format(\n",
    "#             system_message=PROMPT,\n",
    "#             prompt=user_input\n",
    "#         ))\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"entities\": [],\n",
    "    \"relationships\": []\n",
    "}\n",
    "\n",
    "def exctract_data(response):\n",
    "    # Extract Entities\n",
    "    for entity in response.get(\"entities\", []):\n",
    "        # Check if the entity already exists in the results\n",
    "        name = entity.get(\"name\")\n",
    "        \n",
    "        if name is None:\n",
    "            continue  # Skip if name is not provided\n",
    "\n",
    "        for existing_entity in results[\"entities\"]:\n",
    "            if existing_entity[\"name\"] == name:\n",
    "                description = entity.get(\"description\", False)\n",
    "                if description:\n",
    "                    existing_entity[\"description\"].append(description)\n",
    "                continue\n",
    "\n",
    "        results[\"entities\"].append({\n",
    "            \"name\": entity[\"name\"],\n",
    "            \"description\": [entity[\"description\"]]\n",
    "        })\n",
    "\n",
    "    # Extract Relationships\n",
    "    for relationship in response.get(\"relationships\", []):\n",
    "        # Check if the source and target entities exist in the results\n",
    "        source = relationship.get(\"source\")\n",
    "        description = relationship.get(\"description\", False)\n",
    "        target = relationship.get(\"target\")\n",
    "        \n",
    "        if source is None or target is None:\n",
    "            continue  # Skip if source or target is not provided\n",
    "\n",
    "        for existing_entity in results[\"entities\"]:\n",
    "            if existing_entity[\"name\"] == source:\n",
    "                if description:\n",
    "                    existing_entity[\"description\"].append(description)\n",
    "                continue\n",
    "\n",
    "        results[\"relationships\"].append({\n",
    "            \"source\": source,\n",
    "            \"description\": description if description else [],\n",
    "            \"target\": target\n",
    "        })\n",
    "\n",
    "exctract_data(response1)\n",
    "exctract_data(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dumps, dump\n",
    "with open(\"./output.json\", \"w\") as f:\n",
    "    dump(results, f, indent=4)\n",
    "\n",
    "# with open(\"./output.json\", \"w\", encoding='utf-8') as f:\n",
    "#     f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
